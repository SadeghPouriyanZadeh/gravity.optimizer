{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEVWWGAytvXA"
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "H_adi4DUtvXD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBeRwmdutvXO"
   },
   "source": [
    "# Structure Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrEsUnixtvXQ"
   },
   "source": [
    "## Activation Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "icI3PddDtvXR"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "\n",
    "def relu(z, leak_grad=1e-8):\n",
    "    return np.maximum(leak_grad*z, z)\n",
    "\n",
    "\n",
    "def relu_derivative(z, leak_grad=1e-8):\n",
    "    return np.where(z <= 0, leak_grad, 1)\n",
    "\n",
    "\n",
    "def tanh(z):\n",
    "    return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n",
    "\n",
    "\n",
    "def tanh_derivative(z):\n",
    "    return 1 - tanh(z)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ToG5-ziotvXY"
   },
   "outputs": [],
   "source": [
    "activation_functions_dict = {'sigmoid': (sigmoid, sigmoid_derivative),\n",
    "                             'relu': (relu, relu_derivative),\n",
    "                             'tanh': (tanh, tanh_derivative)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A53MQON8tvXh"
   },
   "source": [
    "## Layer Namespace Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7aVttHGxtvXi"
   },
   "outputs": [],
   "source": [
    "class LayerNamespace(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CotRqlYStvXo"
   },
   "source": [
    "## Structure Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fVGGGu36tvXp"
   },
   "outputs": [],
   "source": [
    "class ModelStructure(object):\n",
    "    def __init__(self):\n",
    "        self.__layers = []\n",
    "\n",
    "    def add_input_layer(self, input_features: int):\n",
    "        assert len(self.__layers) == 0, 'Add input layer before other layers'\n",
    "        assert type(input_features) == int, 'Enter integer number'\n",
    "        layer_0 = LayerNamespace()\n",
    "        layer_0.units_number = input_features\n",
    "        self.__layers.append(layer_0)\n",
    "\n",
    "    def add_layer(self, units_number: int, activation_function_name: str,\n",
    "                  keep_prob=1):\n",
    "        assert type(units_number) == int, 'Enter integer number'\n",
    "        assert len(self.__layers) > 0, 'First add input layer'\n",
    "\n",
    "        try:\n",
    "            layer = LayerNamespace()\n",
    "            valid_key = activation_function_name.lower()\n",
    "            layer.activation_function = activation_functions_dict[valid_key][0]\n",
    "            layer.activation_function_derivative = activation_functions_dict[valid_key][1]\n",
    "            layer.units_number = units_number\n",
    "            layer.keep_prob = keep_prob\n",
    "            self.__layers.append(layer)\n",
    "        except KeyError as error:\n",
    "            message = 'Valid activation functions: '\n",
    "            message += ', '.join(activation_functions_dict.keys())\n",
    "            raise KeyError(f'{error} ({message})')\n",
    "\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        assert len(self.__layers) > 1, 'At least nsert one layer'\n",
    "        return self.__layers\n",
    "\n",
    "    def summary(self):\n",
    "        print(f'Input Features: {self.layers[0].units_number}')\n",
    "        total_parameters = 0\n",
    "        pre_units = self.layers[0].units_number\n",
    "        for i, layer in enumerate(self.layers[1:]):\n",
    "            weights = layer.units_number * pre_units\n",
    "            biases = layer.units_number\n",
    "            message_parts = [f'Layer #{i+1}:',\n",
    "                             f'{layer.units_number}',\n",
    "                             f'{layer.activation_function.__name__}',\n",
    "                             f'units with {weights} weights and',\n",
    "                             f'{biases} biases']\n",
    "            print(' '.join(message_parts))\n",
    "            pre_units = layer.units_number\n",
    "            total_parameters += (weights+biases)\n",
    "        print(f'Total Parameters: {total_parameters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-RlP8zmtvX-"
   },
   "source": [
    "# Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOIA9vhitvX_"
   },
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "aQdsZ1fytvYA"
   },
   "outputs": [],
   "source": [
    "def initialize(layers: list):\n",
    "    result = []\n",
    "    previous_layer = layers[0]\n",
    "    for layer in layers[1:]:\n",
    "        shape = (layer.units_number,\n",
    "                 previous_layer.units_number)\n",
    "        # On weight initialization in deep neural networks\n",
    "        scale_dict = {'relu': np.sqrt(2/shape[1]),\n",
    "                      'tanh': np.sqrt(1/shape[1]),\n",
    "                      'sigmoid': np.sqrt((3.6**2)/shape[1])}\n",
    "        func_name = layer.activation_function.__name__\n",
    "        layer.W = np.random.randn(\n",
    "            shape[0], shape[1]) * scale_dict[func_name]\n",
    "\n",
    "        layer.b = np.zeros((shape[0], 1))\n",
    "        result.append(layer)\n",
    "        previous_layer = layer\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aQdsZ1fytvYA"
   },
   "outputs": [],
   "source": [
    "def mini_batch_generator(x: np.ndarray, y: np.ndarray, batch_size: int):\n",
    "    assert x.shape[1] == y.shape[1]\n",
    "    m = x.shape[1]\n",
    "    random_indice = np.random.permutation(m)\n",
    "    shuffled_x = x[:, random_indice]\n",
    "    shuffled_y = y[:, random_indice]\n",
    "\n",
    "    div = divmod(m, batch_size)\n",
    "    for i in range(div[0]):\n",
    "        x_mini_batch = shuffled_x[:, i*batch_size:(i+1)*batch_size]\n",
    "        x_mini_batch = x_mini_batch.reshape(x.shape[0], batch_size)\n",
    "\n",
    "        y_mini_batch = shuffled_y[:, i*batch_size:(i+1)*batch_size]\n",
    "        y_mini_batch = y_mini_batch.reshape(y.shape[0], batch_size)\n",
    "\n",
    "        yield x_mini_batch, y_mini_batch\n",
    "\n",
    "    if div[1]:\n",
    "        x_mini_batch = shuffled_x[:, div[0]*batch_size:]\n",
    "        x_mini_batch = x_mini_batch.reshape(x.shape[0], div[1])\n",
    "\n",
    "        y_mini_batch = shuffled_y[:, div[0]*batch_size:]\n",
    "        y_mini_batch = y_mini_batch.reshape(y.shape[0], div[1])\n",
    "\n",
    "        yield x_mini_batch, y_mini_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Calculators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aQdsZ1fytvYA"
   },
   "outputs": [],
   "source": [
    "def predict(model_output):\n",
    "    prediction = np.where(model_output > 0.5, 1, 0)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def accuracy(prediction, expected):\n",
    "    assert prediction.shape == expected.shape\n",
    "    assert prediction.shape[0] == 1\n",
    "    m = expected.shape[1]\n",
    "    accuracy = np.sum(prediction == expected)/m\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "aQdsZ1fytvYA"
   },
   "outputs": [],
   "source": [
    "def print_metrics(interval=100):\n",
    "    def result_function(epoch, metrics):\n",
    "        if (epoch == 1) or (epoch % interval == 0):\n",
    "            cost = metrics['costs'][-1]\n",
    "            accuracy = metrics['accuracies'][-1]*100\n",
    "            message_parts = [f'Epoch #{epoch:0>4}',\n",
    "                             f'Cost: {cost:.4f}',\n",
    "                             f'Accuracy: {accuracy:.2f}%']\n",
    "\n",
    "            if metrics['validation_costs']:\n",
    "                validation_cost = metrics['validation_costs'][-1]\n",
    "                validation_accuracy = metrics['validation_accuracies'][-1]*100\n",
    "                message_parts.append(\n",
    "                    f'Validation Cost: {validation_cost:.4f}')\n",
    "                message_parts.append(\n",
    "                    f'Validation Accuracy: {validation_accuracy:.2f}%')\n",
    "\n",
    "            print(' | '.join(message_parts))\n",
    "    return result_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Dr2fr-aXtvYW"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(metrics: dict, interval=100):\n",
    "    cost = metrics['costs']\n",
    "    accuracy = metrics['accuracies']\n",
    "    validation_cost = metrics['validation_costs']\n",
    "    validation_accuracies = metrics['validation_accuracies']\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1)\n",
    "\n",
    "    axes[0].plot(cost[::interval], label='Cost')\n",
    "    axes[0].plot(validation_cost[::interval], label='Validation Cost')\n",
    "    axes[0].set_ylabel('Cost')\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(accuracy[::interval], label='Accuracy')\n",
    "    axes[1].plot(validation_accuracies[::interval],\n",
    "                 label='Validation Accuracy')\n",
    "    axes[1].set_ylabel(f'Accuracy')\n",
    "    axes[1].legend()\n",
    "\n",
    "    fig.suptitle(f'iterations (per {interval} epochs)')\n",
    "    fig.tight_layout()\n",
    "    fig.set_size_inches(8, 8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOIA9vhitvX_"
   },
   "source": [
    "## Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aQdsZ1fytvYA"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_cost(Y, Y_hat, epsilon=1e-4):\n",
    "    assert Y.shape == Y_hat.shape, f'{Y.shape} != {Y_hat.shape}'\n",
    "    m = Y.shape[1]  # number of examples\n",
    "    cost = (-1/m) * (np.dot(Y, np.log(Y_hat+epsilon).T) +\n",
    "                     np.dot((1-Y), np.log(1-Y_hat+epsilon).T))\n",
    "    return cost.item()\n",
    "\n",
    "\n",
    "def cross_entropy_derivative(Y, Y_hat, epsilon=1e-4):\n",
    "    return ((1-Y)/(1-Y_hat+epsilon)) - (Y/Y_hat+epsilon)\n",
    "\n",
    "\n",
    "def get_regularization_cost(layers: list, m: int, lambda_: float) -> float:\n",
    "    cost = 0\n",
    "    for layer in layers:\n",
    "        cost += np.sum(np.square(layer.W))\n",
    "    cost *= (1/m) * (lambda_/2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOIA9vhitvX_"
   },
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer Superclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(object):\n",
    "    def initiate_parameters(self, layers: list):\n",
    "        pass\n",
    "    def update_parameters(self, layers: list):\n",
    "        pass\n",
    "    def update_optimizer(self, metrics: dict):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(Optimizer):\n",
    "    def __init__(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def update_parameters(self, layers: list):\n",
    "        for layer in layers:\n",
    "            layer.W = layer.W - self.learning_rate*layer.dW\n",
    "            layer.b = layer.b - self.learning_rate*layer.db\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum(Optimizer):\n",
    "    def __init__(self, learning_rate, beta):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta = beta\n",
    "\n",
    "    def initiate_parameters(self, layers: list):\n",
    "        for layer in layers:\n",
    "            layer.V_dW = np.zeros(layer.W.shape)\n",
    "            layer.V_db = np.zeros(layer.b.shape)\n",
    "        return True\n",
    "            \n",
    "    def update_parameters(self, layers: list):\n",
    "        for layer in layers:            \n",
    "            layer.V_dW = self.beta*layer.V_dW + (1-self.beta)*layer.dW\n",
    "            layer.V_db = self.beta*layer.V_db + (1-self.beta)*layer.db\n",
    "            \n",
    "            layer.W = layer.W - self.learning_rate*layer.V_dW\n",
    "            layer.b = layer.b - self.learning_rate*layer.V_db\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop(Optimizer):\n",
    "    def __init__(self, learning_rate, beta=0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta = beta\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "    def initiate_parameters(self, layers: list):\n",
    "        for layer in layers:\n",
    "            layer.S_dW = np.zeros(layer.W.shape)\n",
    "            layer.S_db = np.zeros(layer.b.shape)\n",
    "        return True\n",
    "            \n",
    "    def update_parameters(self, layers: list):\n",
    "        for layer in layers:            \n",
    "            layer.S_dW = self.beta*layer.S_dW + (1-self.beta)*np.square(layer.dW)\n",
    "            layer.S_db = self.beta*layer.S_db + (1-self.beta)*np.square(layer.db)\n",
    "            \n",
    "            layer.W = layer.W - self.learning_rate*(layer.dW/(np.sqrt(layer.S_dW)+self.epsilon))\n",
    "            layer.b = layer.b - self.learning_rate*(layer.db/(np.sqrt(layer.S_db)+self.epsilon))\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(Optimizer):\n",
    "    def __init__(self, learning_rate, beta_1=0.9, beta_2=0.999):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.epsilon = 1e-8\n",
    "        self.counter = 0\n",
    "\n",
    "    def initiate_parameters(self, layers: list):\n",
    "        self.counter = 0\n",
    "        for layer in layers:\n",
    "            layer.V_dW = np.zeros(layer.W.shape)\n",
    "            layer.V_db = np.zeros(layer.b.shape)\n",
    "            layer.S_dW = np.zeros(layer.W.shape)\n",
    "            layer.S_db = np.zeros(layer.b.shape)\n",
    "            \n",
    "            layer.V_corrected_dW = np.zeros(layer.W.shape)\n",
    "            layer.V_corrected_db = np.zeros(layer.b.shape)\n",
    "            layer.S_corrected_dW = np.zeros(layer.W.shape)\n",
    "            layer.S_corrected_db = np.zeros(layer.b.shape)\n",
    "        return True\n",
    "            \n",
    "    def update_parameters(self, layers: list):\n",
    "        for layer in layers:            \n",
    "            layer.V_dW = self.beta_1*layer.V_dW + (1-self.beta_1)*layer.dW\n",
    "            layer.V_db = self.beta_1*layer.V_db + (1-self.beta_1)*layer.db\n",
    "            layer.S_dW = self.beta_2*layer.S_dW + (1-self.beta_2)*np.square(layer.dW)\n",
    "            layer.S_db = self.beta_2*layer.S_db + (1-self.beta_2)*np.square(layer.db)\n",
    "            \n",
    "            # Apply bias correction\n",
    "            momentum_correction = 1/(1-self.beta_1**(self.counter+1))\n",
    "            rmsprop_correction = 1/(1-self.beta_2**(self.counter+1))\n",
    "\n",
    "            layer.V_corrected_dW = layer.V_dW*momentum_correction\n",
    "            layer.V_corrected_db = layer.V_db*momentum_correction\n",
    "            layer.S_corrected_dW = layer.S_dW*rmsprop_correction\n",
    "            layer.S_corrected_db = layer.S_db*rmsprop_correction\n",
    "        \n",
    "            layer.W = layer.W - self.learning_rate*(layer.V_corrected_dW/(np.sqrt(layer.S_corrected_dW)+self.epsilon))\n",
    "            layer.b = layer.b - self.learning_rate*(layer.V_corrected_db/(np.sqrt(layer.S_corrected_db)+self.epsilon))\n",
    "        self.counter += 1\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mechanic Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MechanicRules(Optimizer):\n",
    "    def __init__(self, learning_rate, g=9.81):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.g = g\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "    def initiate_parameters(self, layers: list):\n",
    "        for layer in layers:\n",
    "            layer.v_hat_W = np.zeros(layer.W.shape)\n",
    "            layer.v_hat_b = np.zeros(layer.b.shape)\n",
    "            \n",
    "            layer.a_hat_W = np.zeros(layer.W.shape)\n",
    "            layer.a_hat_b = np.zeros(layer.b.shape)\n",
    "        return True\n",
    "            \n",
    "    def update_parameters(self, layers: list):\n",
    "        for layer in layers:\n",
    "            s_W = 1 / (np.sqrt(1+np.square(layer.dW))+self.epsilon)\n",
    "            s_b = 1 / (np.sqrt(1+np.square(layer.db))+self.epsilon)\n",
    "            \n",
    "            layer.W = (-0.5*(self.g*layer.dW*s_W + layer.a_hat_W)*(self.learning_rate**2) + layer.v_hat_W*self.learning_rate + layer.W)*s_W\n",
    "            layer.b = (-0.5*(self.g*layer.db*s_b + layer.a_hat_b)*(self.learning_rate**2) + layer.v_hat_b*self.learning_rate + layer.b)*s_b\n",
    "            \n",
    "            layer.v_hat_W = -(self.g*layer.dW*s_W+layer.a_hat_W)*self.learning_rate + layer.v_hat_W\n",
    "            layer.v_hat_b = -(self.g*layer.db*s_b+layer.a_hat_b)*self.learning_rate + layer.v_hat_b\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gravity(Optimizer):\n",
    "    def __init__(self, learning_rate, g=9.81):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.g = g\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "    def initiate_parameters(self, layers: list):\n",
    "        for layer in layers:\n",
    "            layer.v_W = np.zeros(layer.W.shape)\n",
    "            layer.v_b = np.zeros(layer.b.shape)\n",
    "        return True\n",
    "            \n",
    "    def update_parameters(self, layers: list):\n",
    "        for layer in layers:\n",
    "            c1_W = (-self.g*layer.dW) / (1+np.square(layer.dW)+self.epsilon)\n",
    "            c2_W = 1 / (np.sqrt(1+np.square(layer.dW))+self.epsilon)\n",
    "            layer.v_W = c1_W*self.learning_rate + c2_W*layer.v_W\n",
    "                        \n",
    "            c1_b = (-self.g*layer.db) / (1+np.square(layer.db)+self.epsilon)\n",
    "            c2_b = 1 / (np.sqrt(1+np.square(layer.db))+self.epsilon)\n",
    "            layer.v_b = c1_b*self.learning_rate + c2_b*layer.v_b\n",
    "            \n",
    "            layer.W = self.learning_rate*layer.v_W + layer.W\n",
    "            layer.b = self.learning_rate*layer.v_b + layer.b\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kArP_ESqtvYG"
   },
   "source": [
    "## Main Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UVvWPqcotvYO"
   },
   "outputs": [],
   "source": [
    "class Classifier(object):\n",
    "    def __init__(self, model_structure: ModelStructure):\n",
    "        self.input_features = model_structure.layers[0].units_number\n",
    "        self.layers = initialize(model_structure.layers)\n",
    "        self.cost_function = cross_entropy_cost\n",
    "        self.cost_function_derivative = cross_entropy_derivative\n",
    "        self.trained_epochs = 0\n",
    "\n",
    "    def feed_forward(self, X: np.ndarray):\n",
    "        assert X.shape[0] == self.input_features\n",
    "        A_prev = X\n",
    "        for layer in self.layers:\n",
    "            Z = np.dot(layer.W, A_prev) + layer.b\n",
    "            A = layer.activation_function(Z)\n",
    "            A_prev = A\n",
    "        Y_hat = A_prev\n",
    "        return Y_hat\n",
    "\n",
    "    def feed_forward_train(self, X: np.ndarray):\n",
    "        assert X.shape[0] == self.input_features\n",
    "        A_prev = X\n",
    "        for layer in self.layers:\n",
    "            layer.A_previous = A_prev\n",
    "            layer.Z = np.dot(layer.W, A_prev) + layer.b\n",
    "            A_raw = layer.activation_function(\n",
    "                layer.Z)  # Before applying dropout\n",
    "            layer.D = np.random.rand(\n",
    "                *A_raw.shape) < layer.keep_prob  # Dropout Mask\n",
    "            layer.A = (A_raw * layer.D) / layer.keep_prob\n",
    "            A_prev = layer.A\n",
    "        Y_hat = A_prev\n",
    "        return Y_hat\n",
    "\n",
    "    def back_propagate(self, cost_derivative, lambda_):\n",
    "        dA_prev = cost_derivative\n",
    "        m = self.layers[0].Z.shape[1]  # number of examples\n",
    "        for layer in self.layers[::-1]:\n",
    "            layer.dA = (dA_prev*layer.D) / layer.keep_prob\n",
    "            layer.dZ = layer.dA * layer.activation_function_derivative(layer.Z)\n",
    "            layer.dW = (1/m) * np.dot(layer.dZ,\n",
    "                                      layer.A_previous.T) + (lambda_/m)*layer.W\n",
    "            layer.db = 1/m * np.sum(layer.dZ, axis=1, keepdims=True)\n",
    "            dA_prev = np.dot(layer.W.T, layer.dZ)\n",
    "        return True\n",
    "\n",
    "    def fit_minibatch(self, mini_X, mini_Y, lambda_, optimizer):\n",
    "        mini_Y_hat = self.feed_forward_train(mini_X)\n",
    "        cost_derivative = self.cost_function_derivative(mini_Y, mini_Y_hat)\n",
    "        self.back_propagate(cost_derivative, lambda_)\n",
    "        optimizer.update_parameters(self.layers)\n",
    "        return True\n",
    "\n",
    "    def fit(self, X, Y, epochs, batch_size, optimizer,\n",
    "            lambda_=0,\n",
    "            validation_data=None,\n",
    "            metrics_printer=None):\n",
    "        \n",
    "        # Assert Shapes\n",
    "        assert X.shape[1] == Y.shape[1]        \n",
    "        m = X.shape[1]\n",
    "        if validation_data:\n",
    "            assert type(validation_data) == tuple\n",
    "            assert type(validation_data[0]) == np.ndarray\n",
    "            assert type(validation_data[1]) == np.ndarray\n",
    "            assert validation_data[0].shape[0] == X.shape[0]\n",
    "            assert validation_data[1].shape[0] == Y.shape[0]\n",
    "            assert validation_data[0].shape[1] == validation_data[1].shape[1]\n",
    "\n",
    "        metrics = {\n",
    "            'costs': [],\n",
    "            'accuracies': [],\n",
    "            'validation_costs': [],\n",
    "            'validation_accuracies': [],\n",
    "            'learning_rate': []\n",
    "        }\n",
    "        optimizer.initiate_parameters(self.layers)\n",
    "        for _ in range(1, epochs+1):            \n",
    "            mini_batchs = mini_batch_generator(X, Y, batch_size)\n",
    "            for mini_X, mini_Y in mini_batchs:\n",
    "                self.fit_minibatch(mini_X, mini_Y, lambda_, optimizer)\n",
    "\n",
    "            regularization_cost = get_regularization_cost(self.layers, m,\n",
    "                                                          lambda_)\n",
    "\n",
    "            train_Y_hat = self.feed_forward(X)\n",
    "            train_cost = self.cost_function(Y, train_Y_hat)\n",
    "            train_cost += regularization_cost\n",
    "            train_prediction = predict(train_Y_hat)\n",
    "            train_accuracy = accuracy(train_prediction, Y)\n",
    "            metrics['costs'].append(train_cost)\n",
    "            metrics['accuracies'].append(train_accuracy)\n",
    "\n",
    "            if validation_data:\n",
    "                validation_X = validation_data[0]\n",
    "                validation_Y = validation_data[1]\n",
    "                validation_Y_hat = self.feed_forward(validation_X)\n",
    "                validation_cost = self.cost_function(validation_Y,\n",
    "                                                     validation_Y_hat) \n",
    "                validation_cost += regularization_cost\n",
    "                validation_prediction = predict(validation_Y_hat)\n",
    "                validation_accuracy = accuracy(validation_prediction,\n",
    "                                               validation_Y)\n",
    "                metrics['validation_costs'].append(validation_cost)\n",
    "                metrics['validation_accuracies'].append(validation_accuracy)\n",
    "\n",
    "            self.trained_epochs += 1\n",
    "\n",
    "            if metrics_printer:\n",
    "                metrics_printer(self.trained_epochs, metrics)\n",
    "                \n",
    "            optimizer.update_optimizer(metrics)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGPh33-0tvYi"
   },
   "source": [
    "# Test (Binary Classification on Cat vs Dogs Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cats_vs_dogs_dataset(cats_array_path,\n",
    "                             dogs_array_path,\n",
    "                             seed=42, test_size = 0.3):\n",
    "    cats = np.load(cats_array_path)\n",
    "    flatten_cats = cats.reshape(cats.shape[0], -1).T    \n",
    "    dogs = np.load(dogs_array_path)\n",
    "    flatten_dogs = dogs.reshape(dogs.shape[0], -1).T\n",
    "    cats_labels = np.ones((1, flatten_cats.shape[1]))\n",
    "    dogs_labels = np.zeros((1, flatten_dogs.shape[1]))\n",
    "    X = np.concatenate((flatten_cats, flatten_dogs), axis=1)\n",
    "    Y = np.concatenate((cats_labels, dogs_labels), axis=1)    \n",
    "    \n",
    "    m = X.shape[1]\n",
    "    np.random.seed(seed)\n",
    "    random_indice = np.random.permutation(m)\n",
    "    shuffled_X = X[:, random_indice]\n",
    "    shuffled_Y = Y[:, random_indice]\n",
    "    \n",
    "    test_size = int(m*test_size)\n",
    "    train_size = m - test_size\n",
    "    train_X = shuffled_X[:, 0:train_size]\n",
    "    train_Y = shuffled_Y[:, 0:train_size]\n",
    "    test_X = shuffled_X[:, train_size:]\n",
    "    test_Y = shuffled_Y[:, train_size:]\n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_path = Path.joinpath(Path('datasets'),Path('cats_vs_dogs'),Path('cats_array.npy'))\n",
    "dogs_path = Path.joinpath(Path('datasets'),Path('cats_vs_dogs'),Path('dogs_array.npy'))\n",
    "cats_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (12288, 17451)\n",
      "Shape of Y_train: (1, 17451)\n",
      "Shape of X_test: (12288, 7479)\n",
      "Shape of Y_test: (1, 7479)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_cats_vs_dogs_dataset(cats_path, dogs_path)\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of Y_train: {Y_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of Y_test: {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1A91B3E21F0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number = 13\n",
    "print(Y_train[:, number])\n",
    "PIL.Image.fromarray(X_train[:, number].reshape((64, 64, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1A91B3E2910>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number = 7\n",
    "print(Y_test[:, number])\n",
    "PIL.Image.fromarray(X_test[:, number].reshape((64, 64, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "LSBp5zQYtvYx",
    "outputId": "1da7ea41-de0d-4ac0-fc82-1e899cabc9cb"
   },
   "outputs": [],
   "source": [
    "structure = ModelStructure()\n",
    "structure.add_input_layer(test_x.shape[0])\n",
    "structure.add_layer(1000, 'relu', keep_prob=1)\n",
    "structure.add_layer(1000, 'relu', keep_prob=1)\n",
    "structure.add_layer(1, 'sigmoid')\n",
    "structure.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "HJKqQXnatvY5",
    "outputId": "a9979d39-bac8-400a-ecf3-01f54185ed7a"
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "model = Classifier(structure)\n",
    "\n",
    "gd_optimizer = GradientDescent(learning_rate=0.01)\n",
    "\n",
    "momentum_optimizer = Momentum(learning_rate=0.01, beta=0.9)\n",
    "rmsprop_optimizer = RMSprop(learning_rate=0.0002, beta=0.999)\n",
    "adam_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "gravity = Gravity(learning_rate=0.01, g=10)\n",
    "\n",
    "epochs=50\n",
    "metrics = model.fit(X_train, Y_train, epochs, optimizer=gravity,\n",
    "                    batch_size=128, validation_data=(X_test, Y_test),\n",
    "                    lambda_=0, metrics_printer=print_metrics(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rBBC8sDtvZE"
   },
   "source": [
    "## Plot Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "UUHB7gPqtvZG",
    "outputId": "c19e85c7-d635-4f32-faa9-86ea442faf97"
   },
   "outputs": [],
   "source": [
    "plt.xkcd()\n",
    "plot_metrics(metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "neural_network_more_features_added.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
