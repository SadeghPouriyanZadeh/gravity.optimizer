@article{schneider2019deepobs,
  title={DeepOBS: A deep learning optimizer benchmark suite},
  author={Schneider, Frank and Balles, Lukas and Hennig, Philipp},
  journal={arXiv preprint arXiv:1903.05499},
  year={2019}
}
@article{choi2019empirical,
  title={On empirical comparisons of optimizers for deep learning},
  author={Choi, Dami and Shallue, Christopher J and Nado, Zachary and Lee, Jaehoon and Maddison, Chris J and Dahl, George E},
  journal={arXiv preprint arXiv:1910.05446},
  year={2019}
}
@article{soydaner2020comparison,
  title={A Comparison of Optimization Algorithms for Deep Learning},
  author={Soydaner, Derya},
  journal={International Journal of Pattern Recognition and Artificial Intelligence},
  pages={2052013},
  year={2020},
  publisher={World Scientific Publishing Company}
}
@inproceedings{wilson2017marginal,
  title={The marginal value of adaptive gradient methods in machine learning},
  author={Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={4148--4158},
  year={2017}
}
@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}
@article{hinton2012neural,
  title={Neural networks for machine learning},
  author={Hinton, Geoffrey and Srivastava, Nitsh and Swersky, Kevin},
  journal={Coursera, video lectures},
  volume={264},
  number={1},
  year={2012}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@article{polyak1964some,
  title={Some methods of speeding up the convergence of iteration methods},
  author={Polyak, Boris T},
  journal={USSR Computational Mathematics and Mathematical Physics},
  volume={4},
  number={5},
  pages={1--17},
  year={1964},
  publisher={Elsevier}
}
@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization.},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={7},
  year={2011}
}
@article{zeiler2012adadelta,
  title={Adadelta: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}
@inproceedings{sutskever2013importance,
  title={On the importance of initialization and momentum in deep learning},
  author={Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1139--1147},
  year={2013}
}
@article{dozat2016incorporating,
  title={Incorporating nesterov momentum into adam},
  author={Dozat, Timothy},
  year={2016}
}
@inproceedings{sashank2018convergence,
  title={On the convergence of adam and beyond},
  author={Sashank, J REDDI and Satyen, KALE and Sanjiv, KUMAR},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@incollection{bisong2019google,
  title={Google Colaboratory},
  author={Bisong, Ekaba},
  booktitle={Building Machine Learning and Deep Learning Models on Google Cloud Platform},
  pages={59--64},
  year={2019},
  publisher={Springer}
}
@article{luo2019adaptive,
  title={Adaptive gradient methods with dynamic bound of learning rate},
  author={Luo, Liangchen and Xiong, Yuanhao and Liu, Yan and Sun, Xu},
  journal={arXiv preprint arXiv:1902.09843},
  year={2019}
}
@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}
@article{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc V},
  journal={arXiv preprint arXiv:1905.11946},
  year={2019}
}
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}
@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}
@incollection{fukushima1982neocognitron,
  title={Neocognitron: A self-organizing neural network model for a mechanism of visual pattern recognition},
  author={Fukushima, Kunihiko and Miyake, Sei},
  booktitle={Competition and cooperation in neural nets},
  pages={267--285},
  year={1982},
  publisher={Springer}
}
@inproceedings{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={ICML},
  year={2010}
}